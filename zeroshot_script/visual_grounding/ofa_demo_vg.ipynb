{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/lustre/lujinghui1/ofa_transformers_official/\")\n",
    "from ofa.modeling_ofa import OFAModel\n",
    "from ofa.tokenization_ofa import OFATokenizer\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json, cv2\n",
    "import numpy as np\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
    "resolution = 384\n",
    "patch_resize_transform = transforms.Compose([\n",
    "        lambda image: image.convert(\"RGB\"),\n",
    "        transforms.Resize((resolution, resolution), interpolation=Image.BICUBIC),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "def coord2bin(coords, w_resize_ratio, h_resize_ratio):\n",
    "    coord_list = [float(coord) for coord in coords.strip().split()]\n",
    "    bin_list = []\n",
    "    \n",
    "    bin_list += [\"<bin_{}>\".format(int(round(coord_list[0] * w_resize_ratio /512 * (1000 - 1))))]\n",
    "    bin_list += [\"<bin_{}>\".format(int(round(coord_list[1] * h_resize_ratio /512 * (1000 - 1))))]\n",
    "    bin_list += [\"<bin_{}>\".format(int(round(coord_list[2] * w_resize_ratio /512 * (1000 - 1))))]\n",
    "    bin_list += [\"<bin_{}>\".format(int(round(coord_list[3] * h_resize_ratio /512 * (1000 - 1))))]\n",
    "  \n",
    "    return ' '.join(bin_list)\n",
    "\n",
    "def bin2coord(bins, w_resize_ratio, h_resize_ratio):\n",
    "    bin_list = [int(bin[5:-1]) for bin in bins.strip().split()]\n",
    "    coord_list = []\n",
    "    coord_list += [bin_list[0] / (1000 - 1) * 512 / w_resize_ratio]\n",
    "    coord_list += [bin_list[1] / (1000 - 1) * 512 / h_resize_ratio]\n",
    "    coord_list += [bin_list[2] / (1000 - 1) * 512 / w_resize_ratio]\n",
    "    coord_list += [bin_list[3] / (1000 - 1) * 512 / h_resize_ratio]\n",
    "    return coord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/mnt/lustre/lujinghui1/ofa_models/OFA_large'\n",
    "# 加载预训练模型\n",
    "tokenizer = OFATokenizer.from_pretrained(model_dir)\n",
    "model = OFAModel.from_pretrained(model_dir, use_cache=False).to(device)\n",
    "model.config.output_scores = True\n",
    "model.config.return_dict_in_generate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = []\n",
    "with open('/mnt/lustre/lujinghui1/events/anno/trash/trash_7_val.jsonl','r') as fin:\n",
    "    for line in fin.readlines():\n",
    "        line = json.loads(line)\n",
    "        gts.append(line)\n",
    "\n",
    "negatives, positives = [], []\n",
    "for gt in gts:\n",
    "    if len(gt['instances'])>0:\n",
    "        positives.append(gt)\n",
    "    else:\n",
    "        negatives.append(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positives), len(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('/mnt/lustre/lujinghui1/events/data/'+positives[1]['filename'])\n",
    "\n",
    "w, h = img.size\n",
    "print(f'w is {w}; h is {h}')\n",
    "w_resize_ratio = resolution/ w\n",
    "h_resize_ratio = resolution / h\n",
    "\n",
    "\n",
    "ref = 'trash bin'\n",
    "txt = f\" which region does the text ' {ref} ' describe?\"\n",
    "\n",
    "\n",
    "inputs = tokenizer([txt], return_tensors=\"pt\").input_ids.to(device)\n",
    "patch_img = patch_resize_transform(img).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = model.generate(inputs, patch_images=patch_img, num_beams=5, no_repeat_ngram_size=0,num_return_sequences=1) \n",
    "\n",
    "outputs = tokenizer.batch_decode(gen['sequences'], skip_special_tokens=True)\n",
    "print(outputs)\n",
    "print(gen['sequences_scores'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display result\n",
    "img = np.array(img)\n",
    "coord_list = bin2coord(outputs[0], w_resize_ratio, h_resize_ratio)\n",
    "# coord_list = [float(coord) for coord in coords.split()]\n",
    "cv2.rectangle(\n",
    "    img,\n",
    "    (int(coord_list[0]), int(coord_list[1])),\n",
    "    (int(coord_list[2]), int(coord_list[3])),\n",
    "    (0, 255, 0),\n",
    "    3\n",
    ")\n",
    "\n",
    "coord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,50))\n",
    "plt.imshow(img,interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5371dd6fbbabf3dcaf6c8c624628e71658bcb23fd0d94e7cb2fd88516d4754e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
